!pip install -q gradio torch transformers

import gradio as gr
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Charger GPT2 l√©ger
modele = "distilgpt2"
tokenizer = AutoTokenizer.from_pretrained(modele)
model = AutoModelForCausalLM.from_pretrained(modele)

# Fonction de r√©ponse
def chatbot_reponse(message, chat_history):
    inputs = tokenizer.encode(message + tokenizer.eos_token, return_tensors="pt")
    outputs = model.generate(
        inputs,
        max_length=150,
        pad_token_id=tokenizer.eos_token_id,
        do_sample=True,
        top_p=0.95,
        top_k=50
    )
    texte = tokenizer.decode(outputs[0], skip_special_tokens=True)
    chat_history = chat_history + [
        {"role": "user", "content": message},
        {"role": "assistant", "content": texte}
    ]
    return chat_history, ""

# CSS cyberpunk
custom_css = """
#chat_container {background: linear-gradient(135deg, #0f0c29, #302b63, #24243e);
border-radius: 15px; padding: 20px; font-family: 'Courier New', monospace; max-width: 700px; margin:auto;}
#send_button {background-color: #FF00FF !important; color: #FFFFFF !important; border-radius: 10px; font-weight: bold;}
.message_user {background-color: #1e1e2f; color: #00FFFF; padding: 8px 12px; border-radius: 10px; margin-bottom:5px; text-align: right;}
.message_assistant {background-color: #302b63; color:#FF00FF; padding: 8px 12px; border-radius:10px; margin-bottom:5px; text-align:left;}
h1,p {text-align:center;color:#FF00FF;}
"""

# Interface Gradio
with gr.Blocks(css=custom_css) as interface:
    with gr.Column(elem_id="chat_container"):
        gr.Markdown("<h1>ü§ñ Chatbot IA Cyberpunk</h1><p>GPT2 l√©ger + style Discord / Cyberpunk</p>")
        chat_history = gr.Chatbot(elem_id="chat_display", type="messages")
        with gr.Row():
            entree = gr.Textbox(label="Message", placeholder="√âcris ici...", lines=2, interactive=True)
            bouton = gr.Button("Envoyer", variant="primary")
        bouton.click(fn=chatbot_reponse, inputs=[entree, chat_history], outputs=[chat_history, entree])

interface.launch(share=True)
